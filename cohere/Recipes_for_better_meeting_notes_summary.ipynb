{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: we are in the process of updating the links in this notebook. If a link doesn't work, please open an issue and we'll rectify it ASAP. Thanks for your understanding!\n",
        "\n",
        "Links to add:\n",
        "* Cell 1: full system for auto-meeting notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LplM9PSe8djM"
      },
      "source": [
        "# Recipes for better meeting notes summaries\n",
        "\n",
        "This notebook builds on top of [our guide towards building better meeting summaries](https://github.com/cohere-ai/notebooks/blob/22dceb0ce27d73cc27f74cbf2b7c82568cbd26b7/notebooks/Meeting_Summaries_General_%26_LangChain.ipynb). In that guide, we saw how to use Command-R to summarize meeting transcripts with a focus on imparting distinct formatting requirements.\n",
        "\n",
        "In this notebook, we'll cover useful recipes that we use internally to summarize our own meeting notes automatically (see [this guide](https://colab.research.google.com/drive/1BTAAV4ss-iPtxT0ueS7djbIIwPSt3Dpp) for an outline of the full system). We will focus on extracting specific items from the meeting notes, namely:\n",
        "\n",
        "1. Extract action items with assignees (who's on the hook for which task)\n",
        "2. Summarise speaker perspectives (who said what)\n",
        "3. Focus on a narrow topic (what was said about a given topic)\n",
        "\n",
        "Finally, we'll show that prompting the model for 1.-3. can be combined with the formatting instructions covered from our previous guide.\n",
        "\n",
        "We're constantly improving our summarisation capabilities across domains. For more information, you can reach out to us at summarize@cohere.com.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SfEhd3O74--"
      },
      "source": [
        "## Setup\n",
        "\n",
        "You'll need a Cohere API key to run this notebook. If you don't have a key, head to https://cohere.com/ to generate your key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1HzGqnY74bj",
        "outputId": "e822cac4-debf-4f98-d238-0f3f104c44e9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "import ollama\n",
        "\n",
        "model=\"gemma2:9b-instruct-fp16\"\n",
        "num_ctx=8192\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SbVCPxMSD3fs"
      },
      "outputs": [],
      "source": [
        "# We're also defining some util functions for later\n",
        "\n",
        "def pprint(s: Optional[str] = None, maxchars: int = 100):\n",
        "  \"\"\"\n",
        "  Wrap long text into lines of at most `maxchars` (preserves linebreaks occurring in text)\n",
        "  \"\"\"\n",
        "  if not s:\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\n\".join(line.strip() for line in re.findall(rf\".{{1,{maxchars}}}(?:\\s+|$)\", s)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABgVdI7I8Jmk"
      },
      "source": [
        "## Load test data\n",
        "\n",
        "Let's load a meeting transcript to see Command in action!\n",
        "\n",
        "* If you have your own transcript, you can load it to Colab using your favourite method.\n",
        "* If you don't, we'll use a sample from the [QMSum dataset](https://github.com/Yale-LILY/QMSum). QMSum contains cleaned meeting transcripts with [diarised speakers](https://en.wikipedia.org/wiki/Speaker_diarisation); this will be perfect for testing our model's ability to assign action items to specific speakers.\n",
        "* We'll see later that the recipe shared herein isn't limited to meeting notes transcript, but extends to any data with diarised speakers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS-hEiwQ71lv",
        "outputId": "91343727-fef2-497f-fb98-2e0fbffb90fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Manager: Right So this ones a bit unclear to me to be perfectly fair I got this slide from\n",
            "the coach and I am not sure what it is connected to so I guess we are going to discuss our project\n",
            "process and that is going to go into my report So I guess this is the point where we go out of role\n",
            "it looks like and talk about our satisfaction for room for creativity and so forth and how that all\n",
            "worked I guess\n",
            "Marketing: As in within the team or ?\n",
            "Industrial Designer: Right so it is just kind of a open mic kind of thing or\n",
            "Project Manager: I think it is I mmhmm I think so I think hope I am not screwing up an experiment\n",
            "Marketing: you are in charge there you go so\n",
            "Project Manager: But I trust that she would jump in if I was so fair enough right so any thoughts ?\n",
            "Industrial Designer: Are we considering these points here ?\n",
            "Marketing: I think they are starting blocks\n",
            "Project Manager: What do you guys feel about the process ?\n",
            "Marketing: you know I think in general for a days worth of work we actually were relatively\n",
            "productive considering the little amount of input we had going in and the technology has definitely\n",
            "been a help it is really been interesting to try out all this new stuff\n",
            "User Interface: We did not use the whiteboard at all\n",
            "Marketing: No we did not We could now if that would make up for it and I feel like if you guys had\n",
            "been designing in here perhaps that would have changed but because of room constraints does not\n",
            "really matter\n",
            "User Interface: also had I not been intrigued about the pen I do not think I would have used it at\n",
            "all I did not write barely anything\n",
            "Marketing: I think I was taking notes more often than usual just because I liked the pen\n",
            "Project Manager: Was pretty cool tack though\n",
            "Marketing: Mm I am disappointed I did not get a note back from my personal coach\n",
            "Industrial Designer: As you write your personal coach\n",
            "Marketing: but I did not get a response\n",
            "Industrial Designer: What if you get a response two or three months from now ?\n",
            "Marketing: that would be kind of creepy\n",
            "Project Manager: Attempts to contact coach ineffective\n",
            "Marketing: what kind of coaching is that really ? What if I really needed something\n",
            "User Interface: I so n I think there was a lot of room for creativity I do not we could do whatever\n",
            "basically what we wanted until the budget came down on us\n",
            "Marketing: I think so And even then we did get a decent product turned out although it is not\n",
            "everything we wanted it to be\n",
            "Project Manager: That is the brilliance of they had a p they had a peeler in here\n",
            "Marketing: And highly resourceful team mates might I add which is always a plus\n",
            "Project Manager: I think re I thought it was like really creative actually I mean\n",
            "User Interface: I think the teamwork was good as well\n",
            "Industrial Designer: And to prove that we were not wasteful we did not waste a single bit of PlayDoh\n",
            "we used every bit\n",
            "Marketing: Nice All four of those little containers\n",
            "Project Manager: Including the s the multicoloured wave pattern\n",
            "Industrial Designer: My one my one criticism is that we did not have enough colours to work with we\n",
            "only had four was not enough\n",
            "Marketing: You could have developed multiple skins really had you had more colours\n",
            "Industrial Designer: I know it could have been amazing\n",
            "Project Manager: What did you guys think about the the the roles ?\n",
            "Industrial Designer: it is f kind of fun it was I think it was pretty clever because we were never\n",
            "able to get too far off track because the information came in at the right time and kind of filled\n",
            "in the gaps enough At the same time you had enough room to kind of just make things up which was\n",
            "kind of fun\n",
            "Marketing: Though I did feel like th the level of information dropped off severely over the course\n",
            "of the day I mean maybe it is just me but I did not actually get any information for the last\n",
            "presentation at all\n",
            "Project Manager: That is true I I got this spreadsheet\n",
            "Marketing: Nothing I did not even get an email that was it So I feel like that was slightly lacking\n",
            "but then you know fill in the blanks on your own level of creativity upped\n",
            "User Interface: Well I think that was I think that was an issue I kept finding with regard to well\n",
            "no but also when I was reporting about what each of us was doing I was often confused as to what you\n",
            "were doing\n",
            "Marketing: Mmhmm Uhhuh that was not very much\n",
            "User Interface: and then I also felt like you know a lot of our discussion would centre around n\n",
            "specifically what my task was because that was kind of the interface portion which was what the\n",
            "whole project was about but and then in the end I think our jobs kind of melded together a little\n",
            "bit more\n",
            "Industrial Designer: That was fun I think the most helpful thing out of everything was getting the\n",
            "the PowerPoint slides already put together for you because if we did not have that there is no way\n",
            "we could have got all that done in time\n",
            "Marketing: already having the formatted stuff helped a lot Very much so\n",
            "User Interface: And I think your leadership was quite good\n",
            "Project Manager: She said I I I she actually made a comment off boy you are getting into this and I\n",
            "really I think it is true I did get I I felt like I got way too into it\n",
            "Marketing: That is kind of a good thing though\n",
            "Project Manager: I felt like I slipped into it a lot\n",
            "Industrial Designer: It is kind of fun\n",
            "Marketing: you know give the rest of us some structure to work with so hey\n",
            "User Interface: An so is that the first time you have taken on that kind of role ?\n",
            "Project Manager: The first time I have ever done anything like project project management I usually\n",
            "organise crap it is one thing to do you know set up a party with your friends But you guys felt that\n",
            "you could keep the suspension of disbelief kind of like like the role and the ?\n",
            "Marketing: I except for a couple moments where it just got out of hand and I knew we were all lying\n",
            "through our teeth\n",
            "User Interface: I had to admit as soon as w we started I mean as soon as we got the PlayDoh th you\n",
            "know the whole concept of really trying to stick with reality went out the window\n",
            "Project Manager: Maybe in in Legos you know ? Be fun with Legos too like make a remote control or\n",
            "spaceship we used to have spaceship Legos did you guys ever used to build spaceships with Legos\n",
            "everybody knows best spaceships ever you guys felt like there was enough teamwork in all ? No I no I\n",
            "do not know I d I I do not know I do not I I was just I\n",
            "Marketing: Though we did not actually I mean other than minor discussion at meetings there was not\n",
            "except for the actual building\n",
            "Project Manager: It is true huh ?\n",
            "Marketing: but I feel like if this was a team project there actually would have been much more of\n",
            "the collaborative like brainstorming use the board well and this would have been six months worth of\n",
            "work not like three hours worth of meetings\n",
            "User Interface: I think had the issue been more serious we probably would have brainstormed more\n",
            "during our meetings as a team I mean\n",
            "Project Manager: Course I am I am conscious of the idea of the Project Manager asking if you guys\n",
            "feel like there is a team you know it is like kind of like like But Interesting It is kind of\n",
            "fascinating was not it ? I mean the whole process of\n",
            "Industrial Designer: Wonder why is there anything about the way that we got so much inform what was\n",
            "it that kept us from going to the the board ?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If you have your own transcript you would like to test Command on, load it here\n",
        "# transcript = ...\n",
        "\n",
        "# Otherwise, we'll use QMSum\n",
        "# Note this will download the QMSum dataset to your instance\n",
        "qmsum = load_dataset(\"MocktaiLEngineer/qmsum-processed\")\n",
        "# Pick any one transcript\n",
        "transcripts = qmsum[\"validation\"][\"meeting_transcript\"]\n",
        "transcript = transcripts[60]\n",
        "pprint(transcript)\n",
        "pprint()\n",
        "\n",
        "# Measure the number of tokens\n",
        "# num_tokens = len(co.tokenize(transcript).tokens)\n",
        "# pprint(f\"Number of tokens: {num_tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVWdxs3IIqpr"
      },
      "source": [
        "If you've loaded the QMSum dataset, you'll see a back-and-forth dialogue between a Project Manager, an Industrial Designer, and two speakers responsible for Marketing and the User Interface. They seem engaged in a  design discussion with elements of retropsective. Let's see what action items followed from this meeting!\n",
        "\n",
        "Note that if your text length exceeds the context window of Command, you'll need to pre-process that text. Learn more about how to efficiently pre-process long texts at XXX [_include reference_].\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSMTIfnH8xSk"
      },
      "source": [
        "## Build the prompt to extract action items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd3SCjWh9Zh9"
      },
      "source": [
        "To extract action items, no special training is needed with Command!\n",
        "\n",
        "Here's one possible prompt to get action items with the speaker they were assigned to, in the form of bullet points:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QAFIK0OP8vwU"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "## meeting transcript\n",
        "{transcript}\n",
        "\n",
        "## instructions\n",
        "Summarize the meeting transcript above, focusing it exclusively around action items. \\\n",
        "Format your answer in the form of bullets. \\\n",
        "Make sure to include the person each action item is assigned to. \\\n",
        "Don't include preambles, postambles or explanations, but respond only with action items.\n",
        "\n",
        "## summary\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PII_STgJ6oz"
      },
      "source": [
        "We applied a few best practices in constructing this prompt:\n",
        "\n",
        "1. We include a preamble imbuing the model with a persona\n",
        "2. We use Markdown-style headers (i.e. with `##`) to delineate the preamble, the text-to-summarise, the instructions, and the output\n",
        "3. We make the instructions specific: we specify that we want action items with their assignees and specify the expected format\n",
        "\n",
        "Experiment with your own prompts, and let us know which worked best for you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2eK_CvN-5Ms"
      },
      "source": [
        "## Generate action items\n",
        "\n",
        "Let's string together the prompt, and generate action items!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zqeRjrI-3Jm",
        "outputId": "a262bf9b-2980-4daf-bb47-aeec4b8fd68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*  Provide a report to the coach on the project process. - Project Manager\n",
            "*  Contact the personal coach for feedback. - Marketing  \n",
            "*  Consider using the whiteboard in future meetings. - Marketing \n",
            "*  Develop multiple skins if more PlayDoh colors were available. - Industrial Designer  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = prompt_template.format(transcript=transcript)\n",
        "response = ollama.chat(model=model, options={\"num_ctx\": num_ctx}, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "])\n",
        "print(response['message']['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7taNqRTO2_A"
      },
      "source": [
        "Not bad! We can see that the model successfully retrieved the action items that needed an immediate follow-up, and assigned the correct speaker to them. It also formatted the output as bullet points, as requested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anQARVO8RTMh"
      },
      "source": [
        "Sometimes, we need to specify more complex output formats. For instance, we might want to automatically send action items to a company's project management software, which might only accept a certain data format.\n",
        "\n",
        "Say that software accepts only action items as JSON objects where assignees are keys. We could postprocess the previous response into that JSON. Or we could specify those requirements directly into our prompt template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYJ9CPD0ThYT",
        "outputId": "b35e23e1-40e3-489f-a0d7-b1e70e059c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"Project Manager\": [\n",
            "    \"Discuss project process and include in report\",\n",
            "    \"Follow up with coach regarding feedback\"\n",
            "  ],\n",
            "  \"Marketing\": [\n",
            "    \"Explore using the whiteboard in future sessions\"\n",
            "  ],\n",
            "  \"Industrial Designer\": [],\n",
            "  \"User Interface\": []\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt_template_json = \"\"\"\n",
        "## meeting transcript\n",
        "{transcript}\n",
        "\n",
        "## instructions\n",
        "Summarize the meeting transcript above, focusing it exclusively around action items. \\\n",
        "Format your answer in the form of a compilable JSON, where every speaker is a new key. \\\n",
        "Make sure to include the person each action item is assigned to. \\\n",
        "Don't include preambles, postambles or explanations, but respond only with action items.\n",
        "\n",
        "## summary\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template_json.format(transcript=transcript)\n",
        "response = ollama.chat(model=model, options={\"num_ctx\": num_ctx}, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "])\n",
        "print(response['message']['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ3X_kJB1mIM"
      },
      "source": [
        "Great! All we needed was to specify the target output format for Command to obey.\n",
        "\n",
        "Try using different instructions to suit Command's outputs to your needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igIW6yH_ip7_"
      },
      "source": [
        "## How to replicate this pattern for more sub-tasks\n",
        "\n",
        "Command-R readily accommodates changes to the instructions to focus it on other subtasks. As an example, below we adapt the recipe developed for action items to perform two new tasks out-of-the-box:\n",
        "\n",
        "* a. Summarise the meeting from the point of view of every speaker\n",
        "* b. Summarise everything's that been said about a specific topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw9esSWUjIE-"
      },
      "source": [
        "#### a. User perspectives\n",
        "\n",
        "We'll also make the summary extractive, i.e. we encourage the model to reuse passages from the actual meeting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_QSmS5rilHD",
        "outputId": "6013098d-66e7-49ac-b43c-c0a28287e149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "\"Project Manager\": \"I am not sure what this slide is connected to so we are going to discuss our project process and that is going to go into my report.  I think it is I mmhmm I think so I think hope I am not screwing up an experiment. But I trust that she would jump in if I was so fair enough right so any thoughts ?  I thought it was like really creative actually I mean.  She said I I I she actually made a comment off boy you are getting into this and I really I think it is true I did get I I felt like I got way too into it. I usually organise crap it is one thing to do you know set up a party with your friends But you guys felt that you could keep the suspension of disbelief kind of like like the role and the ?.  I do not know I d I I do not know I do not I I was just I.\",\n",
            "\"Marketing\": \"As in within the team or ? I think they are starting blocks. you know I think in general for a days worth of work we actually were relatively productive considering the little amount of input we had going in and the technology has definitely been a help it is really been interesting to try out all this new stuff. No we did not We could now if that would make up for it and I feel like if you guys had been designing in here perhaps that would have changed but because of room constraints does not really matter. I am disappointed I did not get a note back from my personal coach. What kind of coaching is that really ? What if I really needed something. Though I did feel like th the level of information dropped off severely over the course of the day I mean maybe it is just me but I did not actually get any information for the last presentation at all. I did not even get an email that was it So I feel like that was slightly lacking but then you know fill in the blanks on your own level of creativity upped. I except for a couple moments where it just got out of hand and I knew we were all lying through our teeth. I feel like if this was a team project there actually would have been much more of the collaborative like brainstorming use the board well and this would have been six months worth of work not like three hours worth of meetings.\",\n",
            "\"Industrial Designer\": \"Right so it is just kind of a open mic kind of thing or. Are we considering these points here ? My one my one criticism is that we did not have enough colours to work with we only had four was not enough. I know it could have been amazing.  it is f kind of fun it was I think it was pretty clever because we were never able to get too far off track because the information came in at the right time and kind of filled in the gaps enough At the same time you had enough room to kind of just make things up which was kind of fun. The most helpful thing out of everything was getting the the PowerPoint slides already put together for you because if we did not have that there is no way we could have got all that done in time. Wonder why is there anything about the way that we got so much inform what was it that kept us from going to the the board ?\",\n",
            "\"User Interface\": \"I think they are starting blocks.  We did not use the whiteboard at all.  also had I not been intrigued about the pen I do not think I would have used it at all I did not write barely anything. I think I was taking notes more often than usual just because I liked the pen.  I think there was a lot of room for creativity I do not we could do whatever basically what we wanted until the budget came down on us. I kept finding with regard to well no but also when I was reporting about what each of us was doing I was often confused as to what you were doing.  and then I also felt like a lot of our discussion would centre around n specifically what my task was because that was kind of the interface portion which was what the whole project was about but and then in the end I think our jobs kind of melded together a little bit more. I think had the issue been more serious we probably would have brainstormed more during our meetings as a team I mean.\",\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt_template_perspectives = \"\"\"\n",
        "## meeting transcript\n",
        "{transcript}\n",
        "\n",
        "## instructions\n",
        "Summarize the perspectives of every speaker. \\\n",
        "Format your answer in the form of a JSON, where every speaker is a new key. Don't use your own words, but reuse passages from the meeting transcript where possible. \\\n",
        "Don't include preambles, postambles or explanations, but respond only with your summary of each speaker's perspectives.\n",
        "\n",
        "## summary\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template_perspectives.format(transcript=transcript)\n",
        "response = ollama.chat(model=model, options={\"num_ctx\": num_ctx}, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "])\n",
        "print(response['message']['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ESmupp0jNoa"
      },
      "source": [
        "#### b. Topic focus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-JyBrpDilQ_",
        "outputId": "a24edbe7-47ed-4e88-b8b0-ee4de45c8dba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There is no trace of objects shaped like bananas in the provided meeting transcript.  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt_template_focus_topic = \"\"\"\\\n",
        "## meeting transcript\n",
        "{transcript}\n",
        "\n",
        "## instructions\n",
        "Summarize everything that's been said about {topic} in the meeting transcript above. If the meeting transcript doesn't mention {topic}, simply state \\\n",
        "that there is no trace of {topic} in the provided meeting transcript. \\\n",
        "Format your answer in the form of paragraphs. \\\n",
        "Don't include preambles, postambles or explanations, but respond only with your summary of {topic}.\n",
        "\n",
        "## summary\n",
        "\"\"\"\n",
        "\n",
        "# Try new topics here!\n",
        "topic = \"objects shaped like bananas\"\n",
        "\n",
        "prompt = prompt_template_focus_topic.format(transcript=transcript, topic=topic)\n",
        "response = ollama.chat(model=model, options={\"num_ctx\": num_ctx}, messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': prompt,\n",
        "  },\n",
        "])\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ytrkOUYjPXm"
      },
      "source": [
        "Try some of your own prompts and share them back with us at summarize@cohere.com!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
