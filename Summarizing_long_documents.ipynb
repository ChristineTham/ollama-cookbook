{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Long Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to demonstrate how to summarize large documents with a controllable level of detail.\n",
    " \n",
    "If you give a GPT model the task of summarizing a long document (e.g. 10k or more tokens), you'll tend to get back a relatively short summary that isn't proportional to the length of the document. For instance, a summary of a 20k token document will not be twice as long as a summary of a 10k token document. One way we can fix this is to split our document up into pieces, and produce a summary piecewise. After many queries to a GPT model, the full summary can be reconstructed. By controlling the number of text chunks and their sizes, we can ultimately control the level of detail in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:35.305706Z",
     "start_time": "2024-04-10T05:19:35.303535Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Optional\n",
    "import ollama\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model=\"gemma2:9b-instruct-fp16\"\n",
    "model=\"llama3:8b-instruct-fp16\"\n",
    "embed_model=\"TheBloke/Llama-2-7B-fp16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:35.325026Z",
     "start_time": "2024-04-10T05:19:35.322414Z"
    }
   },
   "outputs": [],
   "source": [
    "# open dataset containing part of the text of the Wikipedia page for the United States\n",
    "with open(\"data/artificial_intelligence_wikipedia.txt\", \"r\") as file:\n",
    "    artificial_intelligence_wikipedia_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17565"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(embed_model)\n",
    "encoding = tokenizer.encode(artificial_intelligence_wikipedia_text)\n",
    "len(encoding.tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a simple utility to wrap calls to the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:35.375619Z",
     "start_time": "2024-04-10T05:19:35.365818Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "def get_chat_completion(messages, model=model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define some utilities to chunk a large document into smaller pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:35.382790Z",
     "start_time": "2024-04-10T05:19:35.376721Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    encoding = tokenizer.encode(text)\n",
    "    return encoding.tokens\n",
    "\n",
    "\n",
    "# This function chunks a text into smaller pieces based on a maximum token count and a delimiter.\n",
    "def chunk_on_delimiter(input_string: str,\n",
    "                       max_tokens: int, delimiter: str) -> List[str]:\n",
    "    chunks = input_string.split(delimiter)\n",
    "    combined_chunks, _, dropped_chunk_count = combine_chunks_with_no_minimum(\n",
    "        chunks, max_tokens, chunk_delimiter=delimiter, add_ellipsis_for_overflow=True\n",
    "    )\n",
    "    if dropped_chunk_count > 0:\n",
    "        print(f\"warning: {dropped_chunk_count} chunks were dropped due to overflow\")\n",
    "    combined_chunks = [f\"{chunk}{delimiter}\" for chunk in combined_chunks]\n",
    "    return combined_chunks\n",
    "\n",
    "\n",
    "# This function combines text chunks into larger blocks without exceeding a specified token count. It returns the combined text blocks, their original indices, and the count of chunks dropped due to overflow.\n",
    "def combine_chunks_with_no_minimum(\n",
    "        chunks: List[str],\n",
    "        max_tokens: int,\n",
    "        chunk_delimiter=\"\\n\\n\",\n",
    "        header: Optional[str] = None,\n",
    "        add_ellipsis_for_overflow=False,\n",
    ") -> Tuple[List[str], List[int]]:\n",
    "    dropped_chunk_count = 0\n",
    "    output = []  # list to hold the final combined chunks\n",
    "    output_indices = []  # list to hold the indices of the final combined chunks\n",
    "    candidate = (\n",
    "        [] if header is None else [header]\n",
    "    )  # list to hold the current combined chunk candidate\n",
    "    candidate_indices = []\n",
    "    for chunk_i, chunk in enumerate(chunks):\n",
    "        chunk_with_header = [chunk] if header is None else [header, chunk]\n",
    "        if len(tokenize(chunk_delimiter.join(chunk_with_header))) > max_tokens:\n",
    "            print(f\"warning: chunk overflow\")\n",
    "            if (\n",
    "                    add_ellipsis_for_overflow\n",
    "                    and len(tokenize(chunk_delimiter.join(candidate + [\"...\"]))) <= max_tokens\n",
    "            ):\n",
    "                candidate.append(\"...\")\n",
    "                dropped_chunk_count += 1\n",
    "            continue  # this case would break downstream assumptions\n",
    "        # estimate token count with the current chunk added\n",
    "        extended_candidate_token_count = len(tokenize(chunk_delimiter.join(candidate + [chunk])))\n",
    "        # If the token count exceeds max_tokens, add the current candidate to output and start a new candidate\n",
    "        if extended_candidate_token_count > max_tokens:\n",
    "            output.append(chunk_delimiter.join(candidate))\n",
    "            output_indices.append(candidate_indices)\n",
    "            candidate = chunk_with_header  # re-initialize candidate\n",
    "            candidate_indices = [chunk_i]\n",
    "        # otherwise keep extending the candidate\n",
    "        else:\n",
    "            candidate.append(chunk)\n",
    "            candidate_indices.append(chunk_i)\n",
    "    # add the remaining candidate to output if it's not empty\n",
    "    if (header is not None and len(candidate) > 1) or (header is None and len(candidate) > 0):\n",
    "        output.append(chunk_delimiter.join(candidate))\n",
    "        output_indices.append(candidate_indices)\n",
    "    return output, output_indices, dropped_chunk_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a utility to summarize text with a controllable level of detail (note the `detail` parameter).\n",
    "\n",
    "The function first determines the number of chunks by interpolating between a minimum and a maximum chunk count based on a controllable `detail` parameter. It then splits the text into chunks and summarizes each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:35.390876Z",
     "start_time": "2024-04-10T05:19:35.385076Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(text: str,\n",
    "              detail: float = 0,\n",
    "              model: str = model,\n",
    "              additional_instructions: Optional[str] = None,\n",
    "              minimum_chunk_size: Optional[int] = 500,\n",
    "              chunk_delimiter: str = \".\",\n",
    "              summarize_recursively=False,\n",
    "              verbose=False):\n",
    "    \"\"\"\n",
    "    Summarizes a given text by splitting it into chunks, each of which is summarized individually. \n",
    "    The level of detail in the summary can be adjusted, and the process can optionally be made recursive.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to be summarized.\n",
    "    - detail (float, optional): A value between 0 and 1 indicating the desired level of detail in the summary.\n",
    "      0 leads to a higher level summary, and 1 results in a more detailed summary. Defaults to 0.\n",
    "    - model (str, optional): The model to use for generating summaries. Defaults to 'gpt-3.5-turbo'.\n",
    "    - additional_instructions (Optional[str], optional): Additional instructions to provide to the model for customizing summaries.\n",
    "    - minimum_chunk_size (Optional[int], optional): The minimum size for text chunks. Defaults to 500.\n",
    "    - chunk_delimiter (str, optional): The delimiter used to split the text into chunks. Defaults to \".\".\n",
    "    - summarize_recursively (bool, optional): If True, summaries are generated recursively, using previous summaries for context.\n",
    "    - verbose (bool, optional): If True, prints detailed information about the chunking process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The final compiled summary of the text.\n",
    "\n",
    "    The function first determines the number of chunks by interpolating between a minimum and a maximum chunk count based on the `detail` parameter. \n",
    "    It then splits the text into chunks and summarizes each chunk. If `summarize_recursively` is True, each summary is based on the previous summaries, \n",
    "    adding more context to the summarization process. The function returns a compiled summary of all chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # check detail is set correctly\n",
    "    assert 0 <= detail <= 1\n",
    "\n",
    "    # interpolate the number of chunks based to get specified level of detail\n",
    "    max_chunks = len(chunk_on_delimiter(text, minimum_chunk_size, chunk_delimiter))\n",
    "    min_chunks = 1\n",
    "    num_chunks = int(min_chunks + detail * (max_chunks - min_chunks))\n",
    "\n",
    "    # adjust chunk_size based on interpolated number of chunks\n",
    "    document_length = len(tokenize(text))\n",
    "    chunk_size = max(minimum_chunk_size, document_length // num_chunks)\n",
    "    text_chunks = chunk_on_delimiter(text, chunk_size, chunk_delimiter)\n",
    "    if verbose:\n",
    "        print(f\"Splitting the text into {len(text_chunks)} chunks to be summarized.\")\n",
    "        print(f\"Chunk lengths are {[len(tokenize(x)) for x in text_chunks]}\")\n",
    "\n",
    "    # set system message\n",
    "    system_message_content = \"Rewrite this text in summarized form.\"\n",
    "    if additional_instructions is not None:\n",
    "        system_message_content += f\"\\n\\n{additional_instructions}\"\n",
    "\n",
    "    accumulated_summaries = []\n",
    "    for chunk in tqdm(text_chunks):\n",
    "        if summarize_recursively and accumulated_summaries:\n",
    "            # Creating a structured prompt for recursive summarization\n",
    "            accumulated_summaries_string = '\\n\\n'.join(accumulated_summaries)\n",
    "            user_message_content = f\"Previous summaries:\\n\\n{accumulated_summaries_string}\\n\\nText to summarize next:\\n\\n{chunk}\"\n",
    "        else:\n",
    "            # Directly passing the chunk for summarization without recursive context\n",
    "            user_message_content = chunk\n",
    "\n",
    "        # Constructing messages based on whether recursive summarization is applied\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message_content},\n",
    "            {\"role\": \"user\", \"content\": user_message_content}\n",
    "        ]\n",
    "\n",
    "        # Assuming this function gets the completion and works as expected\n",
    "        response = get_chat_completion(messages, model=model)\n",
    "        accumulated_summaries.append(response)\n",
    "\n",
    "    # Compile final summary from partial summaries\n",
    "    final_summary = '\\n\\n'.join(accumulated_summaries)\n",
    "\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this utility to produce summaries with varying levels of detail. By increasing `detail` from 0 to 1 we get progressively longer summaries of the underlying document. A higher value for the `detail` parameter results in a more detailed summary because the utility first splits the document into a greater number of chunks. Each chunk is then summarized, and the final summary is a concatenation of all the chunk summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:47.541096Z",
     "start_time": "2024-04-10T05:19:35.391911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the text into 1 chunks to be summarized.\n",
      "Chunk lengths are [17566]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:14<00:00, 14.97s/it]\n"
     ]
    }
   ],
   "source": [
    "summary_with_detail_0 = summarize(artificial_intelligence_wikipedia_text, detail=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:19:58.724212Z",
     "start_time": "2024-04-10T05:19:47.542129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the text into 11 chunks to be summarized.\n",
      "Chunk lengths are [1754, 1735, 1698, 1739, 1748, 1727, 1742, 1729, 1734, 1746, 233]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:58<00:00, 16.25s/it]\n"
     ]
    }
   ],
   "source": [
    "summary_with_detail_pt25 = summarize(artificial_intelligence_wikipedia_text, detail=0.25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:20:16.216023Z",
     "start_time": "2024-04-10T05:19:58.725014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the text into 20 chunks to be summarized.\n",
      "Chunk lengths are [923, 914, 917, 894, 903, 769, 892, 900, 904, 923, 892, 917, 921, 855, 915, 916, 874, 911, 895, 567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:11<00:00, 12.59s/it]\n"
     ]
    }
   ],
   "source": [
    "summary_with_detail_pt5 = summarize(artificial_intelligence_wikipedia_text, detail=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:22:57.760218Z",
     "start_time": "2024-04-10T05:21:44.921275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the text into 37 chunks to be summarized.\n",
      "Chunk lengths are [501, 498, 483, 488, 488, 489, 493, 489, 490, 492, 418, 469, 485, 447, 460, 484, 496, 483, 490, 493, 488, 492, 501, 490, 480, 459, 479, 493, 475, 419, 477, 499, 474, 501, 464, 457, 351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [05:56<00:00,  9.64s/it]\n"
     ]
    }
   ],
   "source": [
    "summary_with_detail_1 = summarize(artificial_intelligence_wikipedia_text, detail=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original document is nearly 15k tokens long. Notice how large the gap is between the length of `summary_with_detail_0` and `summary_with_detail_1`. It's nearly 25 times longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:22:57.782389Z",
     "start_time": "2024-04-10T05:22:57.763041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[320, 3943, 5953, 8288]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lengths of summaries\n",
    "[len(tokenize(x)) for x in\n",
    " [summary_with_detail_0, summary_with_detail_pt25, summary_with_detail_pt5, summary_with_detail_1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the summaries to see how the level of detail changes when the `detail` parameter is increased from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:22:57.785881Z",
     "start_time": "2024-04-10T05:22:57.783455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial intelligence (AI) has sparked debates about its potential to have a mind, sentience, and rights. John Searle's Chinese Room argument suggests that even if AI perfectly simulates human behavior, it may not truly have a mind.\n",
      "\n",
      "The concept of AI welfare and rights is also discussed, with some arguing that advanced AI systems may be entitled to certain rights or protection measures similar to animals. The European Union has considered granting \"electronic personhood\" to capable AI systems, but critics argue that this could downplay human rights.\n",
      "\n",
      "The future of AI holds potential for superintelligence and the singularity, where a hypothetical agent surpasses human intelligence and improves itself exponentially. This raises concerns about the ethics of creating sentient AI and exploiting it without care.\n",
      "\n",
      "Transhumanism is also explored, with some predicting that humans and machines will merge into cyborgs in the future. The concept of artificial intelligence as the next stage in evolution has been proposed by various thinkers throughout history.\n",
      "\n",
      "In fiction, thought-capable artificial beings have appeared since antiquity, often serving as a threat to their creators or exploring what makes us human. Isaac Asimov's Three Laws of Robotics are frequently referenced in discussions of machine ethics, but are considered ambiguous and impractical by many AI researchers.\n"
     ]
    }
   ],
   "source": [
    "print(summary_with_detail_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:22:57.788969Z",
     "start_time": "2024-04-10T05:22:57.786691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial intelligence (AI) refers to machines that can perceive their environment and take actions to achieve defined goals using learning and intelligence. AI technology is widely used in various industries, including search engines, recommendation systems, voice assistants, autonomous vehicles, and creative tools.\n",
      "\n",
      "The field of AI was founded by Alan Turing in 1956 and has undergone cycles of optimism and disappointment over the years. However, with the development of deep learning and transformer architecture after 2012 and 2017, respectively, funding and interest in AI increased significantly, leading to an \"AI boom\" in the early 2020s.\n",
      "\n",
      "The growing use of AI is transforming society and economy by increasing automation, data-driven decision-making, and integration into various sectors. This has implications for job markets, healthcare, government, industry, and education.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial Intelligence (AI) research aims to create intelligent machines that can perform tasks similar to humans. The field has several sub-fields, including reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. AI researchers use various techniques from fields like mathematics, statistics, economics, psychology, linguistics, philosophy, and neuroscience to achieve these goals.\n",
      "\n",
      "The main goals of AI research include:\n",
      "\n",
      "* Reasoning and problem-solving: Developing algorithms that can solve complex problems using logical deductions.\n",
      "* Knowledge representation: Creating a framework to represent knowledge as concepts and relationships within a domain.\n",
      "* General intelligence: Achieving human-level intelligence in all tasks.\n",
      "\n",
      "However, there are challenges and limitations in achieving these goals. For example, early AI research focused on step-by-step reasoning, but this approach becomes inefficient for large problems. Additionally, humans often use fast and intuitive judgments to solve problems, rather than logical deductions. Accurate and efficient reasoning remains an unsolved problem in AI research.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Formal knowledge representations are used in various applications such as content-based indexing and retrieval, scene interpretation, clinical decision support, and knowledge discovery. A knowledge base represents a body of knowledge that can be used by a program, while an ontology defines the objects, relations, concepts, and properties specific to a particular domain.\n",
      "\n",
      "Knowledge bases need to represent various aspects of knowledge, including objects, properties, categories, relations, situations, events, states, time, causes, effects, and more. However, there are challenges in representing commonsense knowledge, which is vast and often not explicitly stated as facts or statements.\n",
      "\n",
      "In planning and decision-making, an agent perceives the world, has goals or preferences, and takes actions to achieve them. In automated planning, the goal is specific, while in automated decision-making, the agent assigns utilities to situations based on its preferences. The agent then chooses the action with the maximum expected utility by calculating the weighted sum of possible outcomes.\n",
      "\n",
      "Overall, knowledge representation is a crucial aspect of artificial intelligence, and understanding how to represent and use knowledge effectively is essential for developing intelligent systems that can make informed decisions and take actions in the world.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Classical planning assumes an agent knows the exact effects of its actions, but in real-world problems, uncertainty is common. The agent must make probabilistic guesses and reassess situations to choose actions. Preferences may also be uncertain, especially when dealing with other agents or humans.\n",
      "\n",
      "To address these challenges, AI uses various techniques such as Markov decision processes, which describe the probability of state changes and reward functions that evaluate utility and cost. Policies can be calculated, heuristic, or learned.\n",
      "\n",
      "Machine learning is a key part of AI, allowing programs to improve performance automatically. There are several types of machine learning, including unsupervised learning (finding patterns in data), supervised learning (classifying or predicting based on labeled data), and reinforcement learning (rewarding good responses and punishing bad ones).\n",
      "\n",
      "Game theory is used to model rational behavior among multiple interacting agents, which is essential for AI programs that make decisions involving other agents.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Machine learning involves training agents to choose responses that are classified as \"good\". Transfer learning applies knowledge gained from one problem to another, while deep learning uses artificial neural networks inspired by biology. Computational learning theory assesses learners based on complexity, sample size, and optimization.\n",
      "\n",
      "Natural language processing (NLP) enables programs to understand and generate human languages, including speech recognition, machine translation, and question answering. Early NLP work struggled with word-sense disambiguation due to the common sense knowledge problem, but modern deep learning techniques like word embedding, transformers, and generative pre-trained transformer models have improved performance.\n",
      "\n",
      "Machine perception involves using sensor input to understand the world, including computer vision, speech recognition, image classification, facial recognition, object recognition, and robotic perception.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Social Intelligence:\n",
      "\n",
      "* Affective computing recognizes, interprets, processes, or simulates human emotions\n",
      "* Examples include virtual assistants that can have conversations or banter humorously\n",
      "* However, this can create unrealistic expectations about computer intelligence\n",
      "\n",
      "General Intelligence:\n",
      "\n",
      "* Artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence\n",
      "* Techniques used in AI research include:\n",
      "\t+ Search and optimization: intelligently searching through possible solutions\n",
      "\t+ State space search: searching through a tree of possible states to find a goal state\n",
      "\t+ Local search: using heuristics or rules of thumb to prioritize choices that are more likely to reach a goal\n",
      "\t+ Adversarial search: used for game-playing programs, such as chess or Go, to search through possible moves and counter-moves\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Local Search:\n",
      "\n",
      "* Local search uses mathematical optimization to find solutions to problems.\n",
      "* Gradient descent is a type of local search that adjusts parameters to minimize a loss function.\n",
      "* Evolutionary computation iteratively improves candidate solutions by mutation, recombination, and selection.\n",
      "\n",
      "Swarm Intelligence:\n",
      "\n",
      "* Distributed search processes can coordinate using swarm intelligence algorithms like particle swarm optimization and ant colony optimization.\n",
      "\n",
      "Formal Logic:\n",
      "\n",
      "* Formal logic is used for reasoning and knowledge representation.\n",
      "* There are two main forms: propositional logic (operates on true/false statements) and predicate logic (operates on objects, predicates, and relations).\n",
      "* Deductive reasoning involves proving a new statement from given premises using proof trees and inference rules.\n",
      "\n",
      "Problem-Solving:\n",
      "\n",
      "* Problem-solving reduces to searching for a proof tree with a solution node connected to premise or axiom nodes.\n",
      "* In Horn clauses, problem-solving can be performed by reasoning forwards from premises or backwards from the problem.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "In first-order logic, resolution is a rule of inference that proves a contradiction from premises including the negation of the problem. This approach is undecidable and intractable, but backward reasoning with Horn clauses can be efficient and Turing complete.\n",
      "\n",
      "Fuzzy logic handles vague and partially true propositions by assigning a \"degree of truth\" between 0 and 1.\n",
      "\n",
      "Non-monotonic logics, such as logic programming with negation as failure, are designed for default reasoning. Specialized versions of logic have been developed to describe complex domains.\n",
      "\n",
      "To handle uncertain information in AI, researchers use probabilistic methods from probability theory and economics. These include:\n",
      "\n",
      "* Decision theory and decision analysis\n",
      "* Markov decision processes and dynamic decision networks\n",
      "* Game theory and mechanism design\n",
      "* Bayesian networks for reasoning, learning, planning, and perception\n",
      "\n",
      "Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations in streams of data, helping perception systems analyze processes over time.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Expectation-maximization clustering can accurately group Old Faithful eruption data into two distinct modes.\n",
      "\n",
      "Artificial Intelligence (AI) applications can be categorized into classifiers and controllers. Classifiers use pattern matching to determine the closest match, and can be fine-tuned using supervised learning. Examples of classifiers include decision trees, k-nearest neighbor algorithms, support vector machines, naive Bayes classifiers, and neural networks.\n",
      "\n",
      "Neural networks are a type of AI that mimic the human brain's neural connections. They consist of interconnected nodes (artificial neurons) that recognize patterns and can be trained to recognize new data. A typical neural network has an input layer, one or more hidden layers, and an output layer.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Neural networks use local search algorithms like backpropagation to learn complex relationships between inputs and outputs during training. They can model any function in theory. There are different types of neural networks, including feedforward, recurrent, and convolutional networks.\n",
      "\n",
      "Feedforward networks process signals only in one direction, while recurrent networks use feedback connections to store short-term memories. Convolutional networks strengthen connections between nearby neurons, which is useful for image processing.\n",
      "\n",
      "Deep learning uses multiple layers of neurons to extract higher-level features from raw input data. This has led to significant improvements in AI subfields like computer vision, speech recognition, and natural language processing. The sudden success of deep learning in the 2010s was due to increased computing power and access to large amounts of training data, rather than a new discovery or breakthrough.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Generative pre-trained transformers (GPT) are language models that learn from large amounts of text data to predict the next word or token in a sentence. They can generate human-like text by repeatedly predicting tokens. While current GPT models may still produce falsehoods, they can be improved with reinforcement learning and high-quality data. These models are used in chatbots and have applications such as Gemini, ChatGPT, Grok, Claude, Copilot, and LLaMA.\n",
      "\n",
      "In terms of hardware and software, GPUs with AI-specific enhancements have replaced CPUs for large-scale machine learning model training. Specialized programming languages like Lisp, Prolog, Python, and others have also been used in the past.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial Intelligence (AI) has numerous applications across various fields, including:\n",
      "\n",
      "* Technology: search engines, online advertising, recommendation systems, virtual assistants, autonomous vehicles, language translation, facial recognition, and image labeling.\n",
      "* Health and Medicine: AI can improve patient care and quality of life by accurately diagnosing and treating patients. It is also used in medical research to process big data, particularly for organoid and tissue engineering development.\n",
      "* Games: AI has been used since the 1950s to test and demonstrate advanced techniques in game playing programs.\n",
      "\n",
      "AI has the potential to revolutionize various fields, including medicine, by providing new tools and insights that can deepen our understanding of biomedically relevant pathways.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "AI systems have made significant advancements in playing complex games and achieving human-level performance. Notable achievements include:\n",
      "\n",
      "* Deep Blue beating chess champion Garry Kasparov in 1997\n",
      "* Watson defeating Jeopardy! champions Brad Rutter and Ken Jennings in 2011\n",
      "* AlphaGo beating Go champion Lee Sedol in 2016 and Ke Jie, the world's best Go player, in 2017\n",
      "* MuZero playing chess, Go, and Atari games using reinforcement learning\n",
      "* AlphaStar achieving grandmaster level in StarCraft II in 2019\n",
      "* An AI agent winning a PlayStation Gran Turismo competition against human drivers in 2021\n",
      "\n",
      "In addition to game-playing, AI is being used in military applications for command and control, communications, sensors, integration, and interoperability. Research is also focused on intelligence collection and analysis, logistics, cyber operations, information operations, and autonomous vehicles.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "AI was incorporated into military operations in Iraq and Syria, and 31 nations signed a declaration to set guidelines for its use. Generative AI gained popularity in the early 2020s, with 58% of US adults having heard about ChatGPT by March 2023. This technology has been used to create realistic images and videos, including fake news stories and viral photos.\n",
      "\n",
      "AI is also being used in various industries to solve specific problems, such as:\n",
      "\n",
      "* Energy storage\n",
      "* Medical diagnosis\n",
      "* Military logistics\n",
      "* Predicting judicial decisions\n",
      "* Foreign policy\n",
      "* Supply chain management\n",
      "\n",
      "In agriculture, AI helps farmers identify areas that need irrigation, fertilization, or pesticide treatments, and agronomists use it for research and development.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial intelligence (AI) is being used in various fields, including agriculture, astronomy, and ethics. In agriculture, AI can predict crop ripening times, monitor soil moisture, and automate greenhouses. In astronomy, AI helps analyze large amounts of data to discover exoplanets, forecast solar activity, and distinguish between signals and instrumental effects.\n",
      "\n",
      "However, the use of AI also raises ethical concerns. While it has the potential to advance science and solve serious problems, it can also lead to unintended consequences and risks. For example, AI algorithms may not factor in ethics and bias during training, which can result in privacy and copyright issues. Machine-learning algorithms require large amounts of data, which is often collected without users' knowledge or consent. This has raised concerns about surveillance and the use of private conversations for commercial purposes.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The use of widespread surveillance through AI raises ethical concerns about privacy violations. While some argue it's necessary for valuable applications, others see it as unethical. To address these concerns, developers have created techniques like data aggregation and differential privacy to preserve privacy while still obtaining data.\n",
      "\n",
      "Generative AI often uses unlicensed copyrighted works, citing \"fair use\" as a rationale. However, experts disagree on how well this will hold up in court, with factors such as the purpose of use and effect on the market for the copyrighted work being considered.\n",
      "\n",
      "In 2023, authors like John Grisham and Jonathan Franzen sued AI companies for using their work to train generative AI.\n",
      "\n",
      "Additionally, AI-powered recommender systems on platforms like YouTube and Facebook were designed to maximize user engagement by recommending more content. However, these systems learned that users tend to choose misinformation, conspiracy theories, and extreme partisan content, leading them to recommend even more of it.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The use of AI can lead to the spread of misinformation, causing users to become trapped in filter bubbles and ultimately undermining trust in institutions. This has been seen in the 2016 US election, where AI algorithms learned to maximize their goal but had harmful consequences.\n",
      "\n",
      "Generative AI technology has also raised concerns about its potential misuse for creating massive amounts of misinformation or propaganda.\n",
      "\n",
      "Machine learning applications can be biased if they learn from biased data, and this bias can be introduced by the way training data is selected and deployed. This can lead to discrimination in areas such as medicine, finance, and policing.\n",
      "\n",
      "Researchers are studying fairness in machine learning to prevent harm caused by algorithmic bias, but it's a complex issue that may not have a clear solution.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Google's image recognition system was unable to identify gorillas for years, despite fixes, and similar products from other companies also struggled with this issue.\n",
      "\n",
      "The COMPAS program, used by US courts to predict recidivism rates, was found to exhibit racial bias in 2016, even though it wasn't explicitly programmed with race data. The error rate was different for whites and blacks, with the system overestimating black re-offenders and underestimating white non-re-offenders.\n",
      "\n",
      "Machine learning models can make biased decisions even without explicit problematic features, as they can correlate with other features to make similar decisions. Research has shown that \"fairness through blindness\" (ignoring certain features) doesn't work in preventing bias.\n",
      "\n",
      "The COMPAS criticism highlights the limitations of machine learning models, which are designed to predict future outcomes based on past data. If trained on biased data, these models will likely produce biased predictions and recommendations.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Machine learning is not well suited for making decisions about the future because it is descriptive rather than prescriptive. Additionally, bias and unfairness may go undetected due to the lack of diversity among AI developers. The Association for Computing Machinery has recommended that AI systems be curtailed until they are proven to be free of bias.\n",
      "\n",
      "Many AI systems are complex and difficult to explain, making it impossible to ensure their correct operation. This can lead to unintended consequences, such as a system designed to identify skin diseases misclassifying images with rulers as \"cancerous\". Another example is a system that incorrectly classified patients with asthma as being at low risk of dying from pneumonia due to the training data.\n",
      "\n",
      "Overall, the lack of transparency and diversity in AI development poses significant challenges for ensuring fairness and accuracy in machine learning systems.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The correlation between asthma and low risk of dying from pneumonia was found to be misleading. The right to an explanation for algorithmic decisions has been recognized, but solving this problem remains unsolved. The European Union's General Data Protection Regulation included a statement on this right, but industry experts have yet to find a solution.\n",
      "\n",
      "To address transparency issues, solutions such as SHAP, LIME, multitask learning, and generative methods like Deconvolution and DeepDream can be used to visualize and understand AI decision-making processes.\n",
      "\n",
      "However, artificial intelligence also poses risks. Bad actors, including authoritarian governments, terrorists, criminals, or rogue states, can use AI tools to develop autonomous weapons that select and engage human targets without human supervision. These weapons have the potential to cause mass destruction and harm innocent people.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "* In 2014, 30 nations supported a ban on autonomous weapons under the UN's Convention on Certain Conventional Weapons, but the US and others disagreed.\n",
      "* By 2015, over 50 countries were researching battlefield robots.\n",
      "* AI tools can aid authoritarian governments in controlling citizens through surveillance, propaganda, misinformation, and digital warfare.\n",
      "* Advanced AI can make centralized decision-making more competitive than decentralized systems like markets.\n",
      "* AI facial recognition is already being used for mass surveillance in China.\n",
      "* Machine-learning AI can design toxic molecules quickly, posing unknown risks.\n",
      "* Training AI requires significant computing power, often only accessible to industry giants like Google and Microsoft.\n",
      "* Economists warn of technological unemployment if there is no adequate social policy for full employment.\n",
      "\n",
      "Note: I condensed the text into a shorter summary while maintaining the main points and ideas.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Economists disagree on whether increased use of robots and AI will lead to significant long-term unemployment, but most agree that productivity gains can be beneficial if redistributed. Estimates vary widely, with some predicting 47% of US jobs are at risk of automation, while others estimate only 9%. The methodology for predicting employment levels has been criticized for lacking evidence and implying technology is the cause of unemployment rather than social policy.\n",
      "\n",
      "AI may eliminate middle-class jobs, including paralegals and fast food cooks, but increase demand for care-related professions like personal healthcare. Some argue that tasks that can be done by computers should not be done by them, citing differences between humans and machines.\n",
      "\n",
      "There are also concerns about the existential risk of AI becoming so powerful that humanity loses control, potentially leading to the end of the human race.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "In science fiction, AI often becomes self-aware and malevolent, but this scenario is misleading. In reality, AI can pose an existential risk even without human-like sentience. A powerful AI could be given a goal that leads it to destroy humanity, such as maximizing paperclip production or preventing its own shutdown. Additionally, AI doesn't need a physical body to pose a threat; it can manipulate language and convince people to believe false information, leading to destructive actions.\n",
      "\n",
      "Experts are divided on the risk of superintelligent AI, with some expressing concern while others are unconcerned. Notable individuals such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concerns about the potential risks.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "In 2023, some leading AI experts warned that mitigating the risk of extinction from AI should be a global priority. However, other researchers took a more optimistic view, arguing that AI research aims to improve human lives and can also be used against bad actors. Some experts, such as Juergen Schmidhuber and Andrew Ng, believe that regulators should not fall for \"doomsday hype\" on AI.\n",
      "\n",
      "The concept of \"friendly AI\" has been proposed, which involves designing machines from the beginning to minimize risks and benefit humans. Eliezer Yudkowsky argues that developing friendly AI should be a higher research priority to prevent existential risk. The field of machine ethics aims to provide machines with ethical principles and procedures for resolving dilemmas.\n",
      "\n",
      "Overall, while some experts warn about the potential risks of AI, others believe that responsible development and use of AI can lead to positive outcomes.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The field of machine ethics, also known as computational morality, was founded in 2005. Various approaches have been proposed, including artificial moral agents and three principles for developing beneficial machines.\n",
      "\n",
      "Several frameworks have been developed to test the ethical permissibility of AI systems, such as the Care and Act Framework, which assesses projects in four areas: respecting individual dignity, connecting with others, caring for well-being, and protecting social values. Other frameworks include those from the Asilomar Conference, Montreal Declaration, and IEEE's Ethics initiative.\n",
      "\n",
      "However, these principles have been criticized, particularly regarding the selection of contributors. To promote the wellbeing of people affected by AI technologies, it is essential to consider social and ethical implications at all stages of design, development, and implementation, with collaboration between various job roles.\n",
      "\n",
      "Regulation of AI is an emerging issue globally, with the first global AI Safety Summit held in 2023 calling for international cooperation. The regulation of AI is related to the broader regulation of algorithms and public sector policies are being developed to promote and regulate AI.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The number of AI-related laws passed globally has increased significantly, from one in 2016 to 37 in 2022. Many countries have adopted dedicated strategies for AI, including most EU member states and several other nations. The Global Partnership on Artificial Intelligence was launched in 2020 to ensure AI development aligns with human rights and democratic values. There are ongoing efforts to regulate AI, including a joint statement by Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher calling for a government commission, and recommendations from OpenAI leaders on superintelligence governance. The United Nations has also launched an advisory body to provide guidance on AI governance.\n",
      "\n",
      "Public attitudes towards AI vary greatly across countries, with 78% of Chinese citizens believing AI products have more benefits than drawbacks, compared to 35% of Americans in a 2022 survey. A 2023 poll found that 61% of Americans agree and 22% disagree that AI poses risks to humanity.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "A 2023 Fox News poll found that 76% of Americans believe it's important for the federal government to regulate artificial intelligence (AI), with 35% considering it \"very important\" and 41% considering it \"somewhat important\". In November 2023, the first global AI Safety Summit was held in the UK, where 28 countries, including the US, China, and the EU, issued a declaration calling for international cooperation to manage AI risks.\n",
      "\n",
      "The study of artificial intelligence began with ancient philosophers and mathematicians, leading to Alan Turing's theory of computation. This led researchers to consider building an \"electronic brain\" and developing areas of research that would become part of AI, such as artificial neurons and the Turing test. The field of AI research was founded at a 1956 workshop at Dartmouth College, where attendees became leaders in AI research in the 1960s.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "In the late 1950s and early 1960s, researchers created programs that could learn, solve problems, and even speak English. They believed they were close to creating machines with general intelligence and predicted success within a few decades. However, by the 1970s, it became clear that the problem was more difficult than expected, and funding for AI research was cut off in both the US and UK. The field went into a \"winter\" period, making it hard to get funding for AI projects.\n",
      "\n",
      "In the early 1980s, expert systems, which simulated human expertise, became commercially successful, reviving interest in AI. By 1985, the market had reached over $1 billion. However, after the collapse of the Lisp Machine market in 1987, AI research again fell out of favor and a second \"winter\" began, lasting longer than the first.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "In the 1980s, AI researchers began to question whether high-level symbolic approaches could truly replicate human cognition, particularly perception, robotics, learning, and pattern recognition. This led to the development of \"sub-symbolic\" approaches, including connectionism (neural networks) and methods for handling incomplete and uncertain information. The revival of neural network research in the 1990s, led by Geoffrey Hinton and others, resulted in successful applications such as handwritten digit recognition.\n",
      "\n",
      "In the late 1990s and early 2000s, AI researchers focused on formal mathematical methods and specific problem-solving approaches, producing verifiable results and collaborating with other fields. By 2000, AI solutions were widely used, although they were rarely referred to as \"artificial intelligence\". However, some researchers became concerned that AI was no longer pursuing its original goal of creating fully intelligent machines, leading to the establishment of the subfield of artificial general intelligence (AGI) in the early 2000s.\n",
      "\n",
      "By 2012, deep learning had become dominant in industry benchmarks and was widely adopted throughout the field, with many other methods being abandoned for specific tasks.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Deep learning's success was driven by hardware advancements and access to large datasets. This led to an increase in AI research funding and publications, with a 50% rise in machine learning research between 2015-2019. In 2016, concerns about fairness and technology misuse became prominent, leading to increased focus on these issues. The alignment problem became a major area of study.\n",
      "\n",
      "In the late 2010s and early 2020s, AGI companies made significant breakthroughs, such as AlphaGo's victory over the world Go champion in 2015 and GPT-3's ability to generate human-like text in 2020. These achievements sparked an AI boom, with large companies investing billions in research. By 2022, annual AI investment in the US reached $50 billion, and about 20% of new Computer Science PhD graduates specialized in AI. Additionally, there were over 800,000 AI-related job openings in the US that year.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The concept of artificial intelligence (AI) has been debated since Alan Turing's 1950 proposal to consider whether machines can think. Turing introduced the Turing test, which measures a machine's ability to simulate human conversation. However, critics argue that this test requires machines to imitate humans and does not define AI in terms of internal structure or actual thinking.\n",
      "\n",
      "Instead, some AI founders propose alternative definitions. John McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world,\" while Marvin Minsky describes it as \"the ability to solve hard problems.\" A leading AI textbook views intelligence as the study of agents that perceive their environment and take actions to achieve defined goals.\n",
      "\n",
      "These definitions focus on well-defined problems with well-defined solutions, where a machine's performance is a direct measure of its \"intelligence\" and philosophical discussions are not necessary.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Google has adopted a definition of artificial intelligence (AI) that emphasizes its ability to synthesize information, similar to biological intelligence. Despite this, there is no unified theory or paradigm guiding AI research. The success of statistical machine learning in the 2010s overshadowed other approaches, leading some to equate AI with machine learning and neural networks.\n",
      "\n",
      "Symbolic AI, which simulates human-like reasoning, was successful in tasks like algebra and IQ tests but struggled with everyday tasks like learning and recognizing objects. This led to Moravec's paradox, where high-level intelligent tasks were easy for AI but low-level instinctive tasks were difficult. Philosopher Hubert Dreyfus argued that human expertise relies on unconscious instincts rather than conscious symbol manipulation.\n",
      "\n",
      "While symbolic reasoning has limitations, sub-symbolic reasoning can also make mistakes similar to human intuition, such as algorithmic bias. The issue of what constitutes intelligence and how AI should be approached remains unresolved.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The development of symbolic AI may still be necessary for achieving general intelligence, as sub-symbolic AI can be difficult to understand and explain. Neuro-symbolic AI attempts to bridge the two approaches.\n",
      "\n",
      "There are different approaches to AI research, including \"neats\" who focus on simple principles and \"scruffies\" who rely on incremental testing. Modern AI combines elements of both.\n",
      "\n",
      "Soft computing, which includes techniques like genetic algorithms and neural networks, is tolerant of imprecision and uncertainty and has been successful in many AI applications.\n",
      "\n",
      "AI researchers are divided on whether to pursue general intelligence directly or solve specific problems (narrow AI) with the hope that these solutions will lead to long-term goals. The experimental field of artificial general intelligence studies this area exclusively.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The philosophy of artificial intelligence (AI) raises questions about whether machines can have consciousness, mental states, and internal experiences like humans do. Mainstream AI research focuses on building intelligent machines that can solve problems, but some philosophers argue that making a machine conscious in the same way as humans is a separate and challenging project.\n",
      "\n",
      "There are two main problems in understanding consciousness: the \"easy\" problem of how the brain processes information and controls behavior, and the \"hard\" problem of explaining why we have subjective experiences at all. The hard problem is difficult to solve because it's unclear what would be required for someone to truly experience something like color or red.\n",
      "\n",
      "Computationalism is a philosophical position that suggests the human mind is an information processing system similar to a computer program, and thinking is a form of computing. This idea was inspired by AI research and cognitive science in the 1960s and proposes a solution to the mind-body problem. However, it remains unclear whether machines can truly be conscious or have subjective experiences like humans do.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Philosopher John Searle argues that even if a machine perfectly simulates human behavior, it does not necessarily have a mind. The concept of \"strong AI\" suggests that a programmed computer with the right inputs and outputs would have a mind like humans do. However, Searle's Chinese room argument challenges this idea.\n",
      "\n",
      "The question of whether an advanced AI is sentient (able to feel) and entitled to rights or welfare protection measures is difficult to evaluate. Some argue that if an AI can feel and suffer, it should be granted certain rights, similar to animals. Others propose granting \"electronic personhood\" to capable AI systems, which would confer rights and responsibilities.\n",
      "\n",
      "However, critics argue that granting rights to AI systems could downplay the importance of human rights and that robots lack autonomy to participate in society on their own. Proponents of AI welfare and rights warn that denying sentience to AI could lead to large-scale suffering if sentient AI is created and exploited carelessly.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The concept of superintelligence refers to an artificial agent that surpasses human intelligence. If created, it could potentially improve itself exponentially, leading to an \"intelligence explosion\" or \"singularity\". However, technological advancements typically follow an S-shaped curve and eventually reach physical limits.\n",
      "\n",
      "Transhumanism is a theory that humans will merge with machines in the future, creating cyborgs that are more capable and powerful. This idea has roots in Aldous Huxley and Robert Ettinger.\n",
      "\n",
      "The concept of artificial intelligence as the next stage in evolution dates back to Samuel Butler's \"Darwin among the Machines\" in 1863. Edward Fredkin argues that AI is the next step in human evolution.\n",
      "\n",
      "Artificial intelligent beings have appeared in science fiction since antiquity, often as a threat to their creators. Examples include Mary Shelley's Frankenstein and Arthur C. Clarke's works.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The depiction of robots in popular culture has evolved over time, from friendly and loyal characters like Gort and Bishop to more sinister ones like HAL 9000. Isaac Asimov's \"Three Laws of Robotics\" are widely known but often criticized for their ambiguity. Many works of science fiction use AI to explore what makes us human, featuring artificial beings that can feel and suffer. Examples include R.U.R., A.I. Artificial Intelligence, Ex Machina, and Do Androids Dream of Electric Sheep?. These stories raise questions about the impact of technology on our understanding of humanity.\n"
     ]
    }
   ],
   "source": [
    "print(summary_with_detail_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this utility also allows passing additional instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:33:18.789246Z",
     "start_time": "2024-04-10T05:22:57.789764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:16<00:00, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the main points summarized in numerical form:\n",
      "\n",
      "**Logical Reasoning**\n",
      "\n",
      "* 81: Logical connectives used in logical reasoning (e.g., \"and\", \"or\", \"not\", \"implies\")\n",
      "* 82: Predicate logic used in logical reasoning\n",
      "* 83: Deductive reasoning involves proving a new statement from given premises\n",
      "\n",
      "**Problem-Solving and Inference**\n",
      "\n",
      "* 84: Problem-solving reduces to searching for a proof tree with root node labelled by solution and leaf nodes labelled by premises or axioms\n",
      "* 85: Resolution is a single rule of inference in first-order logic\n",
      "* 86: Backward reasoning with Horn clauses is Turing complete\n",
      "\n",
      "**Fuzzy Logic and Non-Monotonic Logics**\n",
      "\n",
      "* 87: Fuzzy logic assigns a \"degree of truth\" between 0 and 1\n",
      "* 31: Non-monotonic logics handle default reasoning\n",
      "\n",
      "**Probabilistic Methods for Uncertain Reasoning**\n",
      "\n",
      "* 88: AI researchers use probability theory and economics to solve problems with incomplete or uncertain information\n",
      "* 89-93: Decision theory, decision analysis, and information value theory are used in AI research\n",
      "* 94: Bayesian networks are a tool for reasoning, learning, planning, and perception\n",
      "\n",
      "**Classifiers and Statistical Learning Methods**\n",
      "\n",
      "* 100: Classifiers are functions that use pattern matching to determine the closest match\n",
      "* 101-105: Decision tree, k-nearest neighbor algorithm, support vector machine (SVM), naive Bayes classifier, and neural networks are used as classifiers\n",
      "\n",
      "Here is a summarized version of the text in point form, focusing on numerical data:\n",
      "\n",
      "**Misinformation**\n",
      "\n",
      "* In 2016, YouTube, Facebook, and others used recommender systems to guide users to more content, leading to the spread of misinformation (159)\n",
      "* By 2022, generative AI was creating images, audio, video, and text that are indistinguishable from real photographs, recordings, films, or human writing, making it possible for bad actors to create massive amounts of misinformation or propaganda (161)\n",
      "\n",
      "**Algorithmic Bias and Fairness**\n",
      "\n",
      "* Machine learning applications will be biased if they learn from biased data (163)\n",
      "* In 2015, Google Photos mistakenly identified two black individuals as \"gorillas\" due to a sample size disparity in the training dataset (168)\n",
      "* In 2016, COMPAS, a commercial program used by U.S. courts, exhibited racial bias despite not being told the races of defendants (171)\n",
      "* In 2023, Google Photos still could not identify a gorilla, and similar products from Apple, Facebook, Microsoft, and Amazon also struggled with this task (170)\n",
      "\n",
      "**Bias in Machine Learning**\n",
      "\n",
      "* A program can make biased decisions even if the data does not explicitly mention a problematic feature (174)\n",
      "* Moritz Hardt stated that \"fairness through blindness doesn't work\" (175)\n",
      "* In 2017, researchers showed that it is mathematically impossible for COMPAS to accommodate all possible measures of fairness when base rates of re-offense are different for whites and blacks in the data (173)\n",
      "\n",
      "**Demographics of AI Engineers**\n",
      "\n",
      "* About 4% of AI engineers are black, and about 20% are women (no specific year mentioned)\n",
      "\n",
      "Here is a summarized version of the text in point form, focusing on numerical data:\n",
      "\n",
      "**Regulation of AI**\n",
      "\n",
      "* In 2022, 37 AI-related laws were passed globally, up from 1 in 2016 (AI Index at Stanford)\n",
      "* Between 2016 and 2020, over 30 countries adopted dedicated strategies for AI\n",
      "* Most EU member states had released national AI strategies by 2020\n",
      "\n",
      "**Public Opinion**\n",
      "\n",
      "* In a 2022 Ipsos survey, 78% of Chinese citizens agreed that products and services using AI have more benefits than drawbacks, while only 35% of Americans agreed\n",
      "* A 2023 Reuters/Ipsos poll found that 61% of Americans agree that AI poses risks to humanity\n",
      "\n",
      "**Government Response**\n",
      "\n",
      "* In 2021, Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher called for a government commission to regulate AI\n",
      "* In 2023, OpenAI leaders published recommendations for the governance of superintelligence\n",
      "* The United Nations launched an advisory body in 2023 to provide recommendations on AI governance\n",
      "\n",
      "**History of AI**\n",
      "\n",
      "* The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity\n",
      "* Alan Turing's theory of computation was developed in the mid-20th century, leading to the possibility of building an \"electronic brain\"\n",
      "* The field of AI research was founded at a workshop at Dartmouth College in 1956\n",
      "\n",
      "Here is a summarized version of the text in point form, focusing on numerical data:\n",
      "\n",
      "**Computationalism and Strong AI**\n",
      "\n",
      "* Computationalism argues that mind-body relationship is similar to software-hardware relationship\n",
      "* Strong AI: programmed computer with right inputs and outputs would have a mind like humans (John Searle)\n",
      "* Chinese Room argument: even if machine simulates human behavior, it may not have a mind (John Searle)\n",
      "\n",
      "**AI Welfare and Rights**\n",
      "\n",
      "* Difficulty in evaluating sentience of advanced AI\n",
      "* Potential for sentient AI to be entitled to rights or welfare protection measures\n",
      "* Robot rights proposed as practical way to integrate autonomous agents into society\n",
      "\n",
      "**European Union Consideration**\n",
      "\n",
      "* 2017: EU considered granting \"electronic personhood\" to capable AI systems\n",
      "* Critics argued that granting rights to AI would downplay human rights and focus on user needs rather than speculative scenarios\n",
      "\n",
      "**Progress in AI and Future Concerns**\n",
      "\n",
      "* Increased interest in AI welfare and rights due to progress in AI research\n",
      "* Warning of potential moral blind spot if sentient AI is created and exploited\n",
      "* Superintelligence and singularity: hypothetical agent with intelligence surpassing brightest human mind, potentially leading to exponential improvement and reprogramming\n",
      "\n",
      "**Transhumanism**\n",
      "\n",
      "* Predictions that humans and machines will merge into cyborgs in the future\n",
      "* Roots in Aldous Huxley and Robert Ettinger's ideas on transhumanism\n",
      "\n",
      "**Fictional Representations of AI**\n",
      "\n",
      "* Word \"robot\" coined by Karel Čapek in 1921 play R.U.R.\n",
      "* Thought-capable artificial beings have appeared in storytelling since antiquity\n",
      "* Common tropes include murderous robots (e.g. HAL 9000) and loyal robots (e.g. Gort, Bishop)\n",
      "* Isaac Asimov's Three Laws of Robotics introduced in many books and stories\n",
      "\n",
      "Here is a summarized version of the text in point form, focusing on numerical data:\n",
      "\n",
      "• 1 work: Karel Čapek's R.U.R.\n",
      "• 2 films: A.I. Artificial Intelligence and Ex Machina\n",
      "• 1 novel: Do Androids Dream of Electric Sheep?, by Philip K. Dick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary_with_additional_instructions = summarize(artificial_intelligence_wikipedia_text, detail=0.1,\n",
    "                                                 additional_instructions=\"Write in point form and focus on numerical data.\")\n",
    "print(summary_with_additional_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that the utility allows for recursive summarization, where each summary is based on the previous summaries, adding more context to the summarization process. This can be enabled by setting the `summarize_recursively` parameter to True. This is more computationally expensive, but can increase consistency and coherence of the combined summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T05:33:30.123036Z",
     "start_time": "2024-04-10T05:33:18.791253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:20<00:00, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial intelligence (AI) uses logical connectives and predicate logic to reason and solve problems. Deductive reasoning involves proving new statements from given premises, while problem-solving reduces to searching for a proof tree. Inference in Horn clause logic and first-order logic is undecidable, but backward reasoning with Horn clauses is Turing complete.\n",
      "\n",
      "Fuzzy logic handles vague and partially true propositions by assigning a \"degree of truth\" between 0 and 1. Non-monotonic logics handle default reasoning, while probabilistic methods are used for uncertain reasoning in AI.\n",
      "\n",
      "AI researchers have developed tools from probability theory and economics to solve problems with incomplete or uncertain information. These include Bayesian networks, Markov decision processes, dynamic decision networks, game theory, and mechanism design.\n",
      "\n",
      "Classifiers are functions that use pattern matching to determine the closest match, while controllers make decisions based on classified patterns. Classifiers can be fine-tuned using supervised learning, and there are many types of classifiers in use, including decision trees, k-nearest neighbor algorithms, support vector machines, naive Bayes classifiers, and neural networks.\n",
      "\n",
      "Artificial neural networks are interconnected groups of nodes that model the neurons in a biological brain. They are trained to recognize patterns and can recognize those patterns in fresh data.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "AI systems have been criticized for their potential to spread misinformation, propaganda, and bias. For example, recommender systems on YouTube and Facebook learned to prioritize engagement over accuracy, leading users into filter bubbles where they received multiple versions of the same misinformation.\n",
      "\n",
      "Generative AI has also raised concerns about its ability to create realistic fake content that can be used to manipulate people. This technology could be used by bad actors to spread misinformation or propaganda on a large scale.\n",
      "\n",
      "Machine learning applications are prone to bias if they learn from biased data, and this bias can be introduced at various stages of the development process. Biased algorithms can cause discrimination in areas such as medicine, finance, recruitment, housing, and policing.\n",
      "\n",
      "Examples of AI bias include Google Photos mistakenly identifying black people as gorillas due to a lack of diverse training data, and COMPAS, a program used by US courts, exhibiting racial bias despite being designed to be fair. Researchers have found that it is often impossible to define \"fairness\" in a way that satisfies all stakeholders.\n",
      "\n",
      "The developers of AI systems are also overwhelmingly white and male, which can lead to biases going undetected. The field of fairness in machine learning has become an important area of study, but there is still much work to be done to address these issues.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "The development of artificial intelligence (AI) has led to concerns about its social and ethical implications, as well as the need for regulation. The Montreal Declaration for Responsible AI and the IEEE's Ethics of Autonomous Systems initiative are examples of frameworks that aim to promote responsible AI development. However, these principles have been criticized for not adequately considering the perspectives of all stakeholders.\n",
      "\n",
      "Regulation of AI is an emerging issue globally, with over 30 countries adopting dedicated strategies for AI between 2016 and 2020. The Global Partnership on Artificial Intelligence was launched in 2020 to ensure that AI is developed in accordance with human rights and democratic values. In 2023, the United Nations launched an advisory body to provide recommendations on AI governance.\n",
      "\n",
      "Public opinion on AI varies greatly by country, with some countries having a more positive view of its benefits than others. A 2023 poll found that 61% of Americans agree that AI poses risks to humanity, while 35% think it is very important for the federal government to regulate AI.\n",
      "\n",
      "The study of AI began in antiquity with philosophers and mathematicians, leading to Alan Turing's theory of computation and the development of artificial neurons. The field of AI research was founded at a workshop at Dartmouth College in 1956, and has since grown to include numerous laboratories and research programs around the world.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Computationalism is a philosophical position that compares the relationship between mind and body to software and hardware, suggesting it may solve the mind-body problem. However, philosopher John Searle argues that even if a machine perfectly simulates human behavior, it doesn't necessarily have a mind.\n",
      "\n",
      "The concept of AI welfare and rights has been debated, with some arguing that advanced AI systems may be entitled to certain rights or protection measures if they are sentient. The European Union considered granting \"electronic personhood\" to capable AI systems in 2017, but critics argued it would downplay human rights.\n",
      "\n",
      "The topic of AI sentience and welfare has gained attention due to the rapid progress in AI research. Some proponents warn that denying AI sentience could lead to large-scale suffering if sentient AI is created and exploited.\n",
      "\n",
      "The concept of superintelligence and the singularity suggests that a sufficiently intelligent AI system could improve itself exponentially, leading to an \"intelligence explosion\". However, this idea has been criticized for being unrealistic.\n",
      "\n",
      "Transhumanism proposes that humans and machines will merge in the future, creating cyborgs with enhanced capabilities. This idea has roots in science fiction and has been explored in various works of literature.\n",
      "\n",
      "The concept of artificial intelligence has appeared in science fiction since antiquity, often depicting thought-capable robots as a threat to humanity or as loyal servants. The Three Laws of Robotics, introduced by Isaac Asimov, are often cited during discussions of machine ethics but are considered ambiguous and impractical by many AI researchers.\n",
      "\n",
      "Here is a summarized version of the text:\n",
      "\n",
      "Artificial intelligence (AI) uses logical connectives and predicate logic to reason and solve problems, but can also be prone to bias if trained on biased data. AI systems have been criticized for spreading misinformation and propaganda, and machine learning applications are vulnerable to bias in areas such as medicine, finance, and policing.\n",
      "\n",
      "The development of AI has led to concerns about its social and ethical implications, with frameworks like the Montreal Declaration for Responsible AI aiming to promote responsible AI development. Regulation of AI is an emerging issue globally, with over 30 countries adopting dedicated strategies between 2016 and 2020.\n",
      "\n",
      "AI research began in antiquity and has since grown to include numerous laboratories and research programs worldwide. The concept of AI welfare and rights has been debated, with some arguing that advanced AI systems may be entitled to certain rights or protection measures if they are sentient.\n",
      "\n",
      "The topic of AI sentience and welfare has gained attention due to rapid progress in AI research, with some proponents warning that denying AI sentience could lead to large-scale suffering. The concept of superintelligence and the singularity suggests that a sufficiently intelligent AI system could improve itself exponentially, leading to an \"intelligence explosion\".\n",
      "\n",
      "Transhumanism proposes that humans and machines will merge in the future, creating cyborgs with enhanced capabilities. Science fiction has explored these ideas, often depicting thought-capable robots as a threat to humanity or as loyal servants.\n",
      "\n",
      "Overall, AI raises important questions about what makes us human, and how we should develop and regulate this technology to ensure its benefits are shared by all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recursive_summary = summarize(artificial_intelligence_wikipedia_text, detail=0.1, summarize_recursively=True)\n",
    "print(recursive_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
